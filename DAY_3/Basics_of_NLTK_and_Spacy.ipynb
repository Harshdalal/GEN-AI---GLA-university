{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#ðŸ”¹ NLTK (Natural Language Toolkit)\n",
        "\n",
        "ðŸ”¸ Overview:\n",
        "\n",
        "A research-focused, open-source library for NLP in Python.\n",
        "\n",
        "Contains a wide variety of tools for linguistic analysis.\n",
        "\n",
        "Comes with corpora, grammars, and trained models.\n",
        "\n",
        "Excellent for learning and experimentation.\n",
        "\n",
        "ðŸ”¸ Key Features:\n",
        "\n",
        "Tokenization\n",
        "\n",
        "Stemming and Lemmatization\n",
        "\n",
        "POS Tagging\n",
        "\n",
        "Named Entity Recognition (NER)\n",
        "\n",
        "Parsing and Chunking\n",
        "\n",
        "Large selection of datasets and text corpora\n",
        "\n",
        "ðŸ”¸ Example:"
      ],
      "metadata": {
        "id": "AwkgFuOs64wY"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p7kLpiSp63xu",
        "outputId": "5510a4b7-7c76-41c7-8213-1aee73fc8258"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger_eng to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger_eng.zip.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tokens: ['Natural', 'Language', 'Processing', 'is', 'interesting', '.']\n",
            "POS Tags: [('Natural', 'JJ'), ('Language', 'NNP'), ('Processing', 'NNP'), ('is', 'VBZ'), ('interesting', 'JJ'), ('.', '.')]\n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('punkt_tab') # Download the missing resource\n",
        "nltk.download('averaged_perceptron_tagger_eng') # Download the missing resource\n",
        "\n",
        "text = \"Natural Language Processing is interesting.\"\n",
        "# Tokenization\n",
        "tokens = nltk.word_tokenize(text)\n",
        "print(\"Tokens:\", tokens)\n",
        "\n",
        "# POS Tagging\n",
        "pos_tags = nltk.pos_tag(tokens)\n",
        "print(\"POS Tags:\", pos_tags)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#ðŸ”¹ spaCy\n",
        "\n",
        "ðŸ”¸ Overview:\n",
        "\n",
        "Industrial-strength NLP library focused on performance and efficiency.\n",
        "\n",
        "Used in production for large-scale text processing.\n",
        "\n",
        "Includes pre-trained pipelines for multiple languages.\n",
        "\n",
        "ðŸ”¸ Key Features:\n",
        "\n",
        "Tokenization\n",
        "\n",
        "POS Tagging\n",
        "\n",
        "Named Entity Recognition (NER)\n",
        "\n",
        "Dependency Parsing\n",
        "\n",
        "Lemmatization\n",
        "\n",
        "Supports custom pipelines and model training\n",
        "\n",
        "ðŸ”¸ Example:"
      ],
      "metadata": {
        "id": "lWH1oeFH7F9c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "\n",
        "# Load English model\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "text = \"Natural Language Processing is interesting.\"\n",
        "doc = nlp(text)\n",
        "\n",
        "# Tokenization\n",
        "tokens = [token.text for token in doc]\n",
        "print(\"Tokens:\", tokens)\n",
        "\n",
        "# POS Tagging\n",
        "pos_tags = [(token.text, token.pos_) for token in doc]\n",
        "print(\"POS Tags:\", pos_tags)\n",
        "\n",
        "# Named Entities\n",
        "entities = [(ent.text, ent.label_) for ent in doc.ents]\n",
        "print(\"Named Entities:\", entities)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PK6H9pbj7DQ1",
        "outputId": "943ec2c1-058f-48ea-be3d-d98a642f58b6"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tokens: ['Natural', 'Language', 'Processing', 'is', 'interesting', '.']\n",
            "POS Tags: [('Natural', 'PROPN'), ('Language', 'PROPN'), ('Processing', 'NOUN'), ('is', 'AUX'), ('interesting', 'ADJ'), ('.', 'PUNCT')]\n",
            "Named Entities: [('Natural Language Processing', 'ORG')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#ðŸ”¹ Comparison Table\n",
        "\n",
        "| Feature            | NLTK                         | spaCy                        |\n",
        "| ------------------ | ---------------------------- | ---------------------------- |\n",
        "| Focus              | Research, education          | Industrial, production-ready |\n",
        "| Speed              | Slower                       | Faster                       |\n",
        "| Ease of Use        | Verbose                      | Compact API                  |\n",
        "| Corpus Included    | Yes (WordNet, Gutenberg etc) | No (but can be added)        |\n",
        "| Model Training     | Limited                      | Supported                    |\n",
        "| Entity Recognition | Yes                          | Yes                          |\n"
      ],
      "metadata": {
        "id": "ws9l_-h97Kmh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#âœ… Summary:\n",
        "\n",
        "Use NLTK if you're learning NLP or working on linguistic experiments.\n",
        "\n",
        "Use spaCy if you're building a production-grade NLP system."
      ],
      "metadata": {
        "id": "iE6qrdzA7Nyk"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Gg-YEhkg7JHZ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}



